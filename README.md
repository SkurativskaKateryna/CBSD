# CBSD
Cognitive Behavioural and Social Data final project  

Authors: CaltranLorenzo, CimbroLetizia,SkurativskaKateryna and Jahanianarange Nahid

Professor: Giuseppe Sartori, Merylin Monaro and Giulia Melis


In this research, we explored the application of the Llama language model to the task of lie detection within the context of memory recall. Our focus was on developing a model capable of identifying subtle linguistic cues that differentiate truthful from deceptive personal narratives. To achieve this, we fine-tuned the Llama model on a specially curated Memory dataset, which included a diverse range of autobiographical accounts labeled as truthful or deceptive. Through an iterative fine-tuning process, we enhanced the modelâ€™s ability to recognize nuanced language patterns that signal deception in recalled memories. The experimental results demonstrated that the fine-tuned Llama model outperformed baseline methods in distinguishing deceptive statements from truthful ones. This work contributes to the advancement of using large language models for lie detection tasks, particularly in forensic, psychological, and security contexts where accurate identification of deceptive communication is essential.


References:

Loconte, R., et al. (2023). Verbal lie detection using Large Language Models. Frontiers in Psychology. PMCID: PMC10739834. https://pmc.ncbi.nlm.nih.gov/articles/PMC10739834/

Massaron, L. (2023). Fine-tune Llama 2 for sentiment analysis. Kaggle. https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis

Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., et al. (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288 [cs.CL]. https://arxiv.org/abs/2307.09288
